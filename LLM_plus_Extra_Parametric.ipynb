{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\Reals}{{\\mathbb{R}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\Emb}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "\\def\\OrderOf#1{\\mathcal{O}\\left( #1 \\right)}\n",
       "%\n",
       "% Expectation operator\n",
       "\\def\\Exp#1{\\underset{#1} {\\operatorname{\\mathbb{E}}} }\n",
       "%\n",
       "% VAE\n",
       "\\def\\prs#1#2{\\mathcal{p}_{#2}(#1)}\n",
       "\\def\\qr#1{\\mathcal{q}(#1)}\n",
       "\\def\\qrs#1#2{\\mathcal{q}_{#2}(#1)}\n",
       "%\n",
       "% Reinforcement learning\n",
       "\\newcommand{\\Actions}{{\\mathcal{A}}} \n",
       "\\newcommand{\\actseq}{A}\n",
       "\\newcommand{\\act}{a}\n",
       "\\newcommand{\\States}{{\\mathcal{S}}}   \n",
       "\\newcommand{\\stateseq}{S}  \n",
       "\\newcommand{\\state}{s}\n",
       "\\newcommand{\\Rewards}{{\\mathcal{R}}}\n",
       "\\newcommand{\\rewseq}{R}\n",
       "\\newcommand{\\rew}{r}\n",
       "\\newcommand{\\transp}{P}\n",
       "\\newcommand{\\statevalfun}{v}\n",
       "\\newcommand{\\actvalfun}{q}\n",
       "\\newcommand{\\disc}{\\gamma}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adding extra-parametric capabilities to a LLM\n",
    "\n",
    "Large Language Models have demonstrated zero and few-shot ability on many tasks.\n",
    "\n",
    "For example:\n",
    "- Question Answering\n",
    "- Mathematical reasoning\n",
    "\n",
    "Moreover, some of this only emerges when the number of parameters becomes very large.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Few/One/Zero shot learning</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/LM_Few_Shot_Accuracy.png\"\" width=80%></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><center>Picture from: https://arxiv.org/pdf/2005.14165.pdf</center></td>\n",
    "    </tr>   \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This suggests that the parameters of the LLM\n",
    "- encode factual knowledge\n",
    "    - book knowledge\n",
    "- encode procedural knowledge\n",
    "    - how to solve a math problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Besides consuming many parameters, encoding facts and procedures in parameters have drawbacks\n",
    "- Factual knowledge is current *only up to the time of training*\n",
    "- When solving math problems, LLM's are known\n",
    "    - to get the procedural reasoning correct\n",
    "    - but make simple arithmetic errors in calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A recent trend has been to augment the LLM with capabilities *external* to its parameters\n",
    "- Factual knowledge obtained from a live source: the Web\n",
    "- Computational abilities by being able to *execute* programs produced by the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can illustrate the difference between parametric and non-parametric knowledge\n",
    "by considering the task of Question Answering\n",
    "- Parametric Knowledge: closed book exam\n",
    "    - all knowledge acquired and stored before inference time\n",
    "- Non-Parametric Knowledge: open book exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Similarly, extra parametric compute can be explained by the analogy\n",
    "about answering a question with a numeric answer that is the solution to an equation\n",
    "- Extra parametric: using a calculator to evaluate the equation \n",
    "- Non extra parametric: solving the equation by hand\n",
    "    - can have the correct equation but incorrect answer due to miscalculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We refer to\n",
    "- the first case as *non-parametric knowledge*\n",
    "- the second case as *extra-parametric compute*\n",
    "\n",
    "We briefly discuss examples of both types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Non-Parametric Knowledge: Retriever-Generator Architecture:\n",
    "\n",
    "The *Retriever-Generator* architecture has two components\n",
    "- A *Retriever* that is able to gather factual knowledge from an external (non-parametric) source\n",
    "- A *Generator* that produces the answer\n",
    "\n",
    "The process is sometimes called *Retrieval Augmented Generation (RAG)*.\n",
    "\n",
    "Details may be found in\n",
    "- this [paper](https://arxiv.org/pdf/2005.11401.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There is also a nice [online article](https://lilianweng.github.io/posts/2020-10-29-odqa/)\n",
    "describing various approaches in the context of the Question Answering task.\n",
    "\n",
    "\n",
    "<img src=\"images/retriever_generator_lweng.png\" width=80%>\n",
    "\n",
    "Attribution: https://lilianweng.github.io/posts/2020-10-29-odqa/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The architecture in the far-right of the diagram is our standard LLM\n",
    "- Question as input\n",
    "- Answer as output\n",
    "\n",
    "In this case: world knowledge is encoded in the parameters of the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The Retriever-Generator architecture is depicted in the middle of the diagram\n",
    "- Question is the input of the Retriever\n",
    "- The Retriever's output (the \"Context\") is the input of the Generator\n",
    "    - e.g., the Top 5 facts retrieved\n",
    "- The Generator (LLM) outputs the answer, given the context obtained by the Retriever\n",
    "\n",
    "In this case: world knowledge is *non-paramteric*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Generator only architecture computes\n",
    "$\\pr{\\y | \\x }$\n",
    " directly.\n",
    "\n",
    "The Generator component of the Retriever-Generator architecture\n",
    "- is *conditioned* \n",
    "- on both question $\\x$ and context $\\z$ \n",
    "- in order to produce answer $\\y$\n",
    "\n",
    "$$\\text{Generator: } \\pr{ \\y | \\x, \\z } = \\pr{ \\y | \\x, \\text{Retriever}(\\x) }$$\n",
    "and ultimately $\\pr{\\y | \\x }$\n",
    "\n",
    "$$\n",
    "\\begin{array} \\\\\n",
    "\\pr{\\y | \\x}_\\text{RAG Sequence} &  = & \\sum_{\\z \\in \\text{Top } K \\,\\pr{ ? | \\x }} { \\pr{ \\z | \\x }_\\eta * \\pr{ \\y | \\x, \\z}   } \\\\\n",
    "& = & \\sum_{\\z \\in \\text{Top } K \\, \\pr{ ? | \\x }} { \\pr{ \\z | \\x }_\\eta \\prod_{i=1}^N { \\pr{ \\y_i | \\x, \\z, \\y_{(1:i-1)}}}   } & \\text{ since } \\pr{ \\y | \\x, \\z} = \\prod_{i=1}^N { \\pr{ \\y_i | \\x, \\z, \\y_{(1:i-1)}} }\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "**Note**\n",
    "\n",
    "The [paper](https://arxiv.org/pdf/2005.11401.pdf) contrasts\n",
    "- \"RAG Sequence\": a single context depending only on question $\\x$\n",
    "- \"RAG Token\": a separate context for each target token $\\y_\\tp$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "The Retriever-Reader architecture (far left of the diagram)\n",
    "- is similar to the Retriever-Generator\n",
    "- but uses a Reader rather than Generator to output the answer\n",
    "    - The answer produced by the Reader is a sub-string of the retrieved facts\n",
    "    - identified by a start/end position\n",
    "    \n",
    "The world knowledge is non-parametric (just like the Retriever-Generator)\n",
    "- but the answer format is much more restricted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Retrieve-Generator: training\n",
    "\n",
    "Both the Retriever and the Generator are parameterized.\n",
    "\n",
    "When the Generator is a LLM\n",
    "- a pre-trained LLM may be used\n",
    "- and its parameters \"fine-tuned\"\n",
    "- not trained from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But the Retriever's parameters need to be learned from scratch via training\n",
    "- depending on how the Retriever obtains external knowledge.\n",
    "- how to generate a \"query\" to the Knowledge Source\n",
    "\n",
    "Here is a diagram\n",
    "\n",
    "<img src=\"images/retriever_generator_training.png\">\n",
    "\n",
    "Attribution: https://arxiv.org/pdf/2005.11401.pdf#page=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extra Parametric Compute\n",
    "\n",
    "The LLM has been shown to have *some* ability to perform math.\n",
    "\n",
    "However: this seems to be one of the capabilities that \"emerge\" only in large models.\n",
    "\n",
    "<img src=\"images/gpt3_arithmetic.png\">\n",
    "\n",
    "Attribution: https://arxiv.org/pdf/2005.14165.pdf#page=21\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The above chart was for a simple arithmetic operation.\n",
    "\n",
    "LLM's have also demonstrated some ability on multi-step reasoning problems.\n",
    "\n",
    "The ability to solve multi-step problems is improved by\n",
    "- [Chain of Thought prompting](https://arxiv.org/pdf/2201.11903.pdf)\n",
    "    - prompting the model to show the solution \"step by step\"\n",
    "- [Show your work prompting](https://arxiv.org/pdf/2112.00114.pdf)\n",
    "\n",
    "Both these methods guide the LLM to produce the answer in small steps, rather than all at once.\n",
    "\n",
    "<table>\n",
    "<img src=\"images/cot_math.png\">\n",
    "\n",
    "Attribution: https://arxiv.org/pdf/2201.11903.pdf#page=19\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In multi-step math problems, LLM's \n",
    "- sometimes generate the correct sequence of solution steps\n",
    "- but fumbles the math (failing to carry the digit)\n",
    "\n",
    "The [CoT paper](https://arxiv.org/pdf/2201.11903.pdf#page=27) calls these \"calculator errors\"\n",
    "- They report that 34% of examples demonstrated calculator errors\n",
    "    - including those with incorrect reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "LLM's perform poorly on a simple mathematical task:\n",
    "- [output the sum of the two inputs, **plus 1**](https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/modified_arithmetic#example)\n",
    "- using few-shot learning\n",
    "\n",
    "<img src=\"images/arith_ex1.png\" width= 70%>\n",
    "\n",
    "GPT-3 has been reported to have **zero** accuracy on this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Even with explicit instruction (as above) the model performs poorly on \"looping\"\n",
    "- What is the $50^{th}$ number in the Fibonacci sequence\n",
    "\n",
    "<img src=\"images/pot_vs_cot.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On the other hand, LLM's have been shown to have the ability to generate programs.\n",
    "\n",
    "[Program of Thoughts Prompting](https://arxiv.org/pdf/2211.12588v3.pdf)\n",
    "is a method\n",
    "- where the LLM is trained (few-shot) to produce *programs* as output\n",
    "- the programs are *executed* by an external module\n",
    "\n",
    "In other words\n",
    "- the LLM tries to get the step by step process correct\n",
    "- and uses an external \"calculator\" to avoid \"doing the math\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Programs of Thought prompting is like Chain of Thought Prompting\n",
    "- prompt asks for a \"step by step\" answer\n",
    "- the exemplars encourage *descriptive variable names*\n",
    "    - improves the ability to generate a correct program ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MRKL systems\n",
    "\n",
    "The Modular Reasoning, Knowledge and Language (MRKL) architecture\n",
    "augments a LLM with the ability to call external systems\n",
    "- Web query\n",
    "- Calendar\n",
    "- Program Execution\n",
    "\n",
    "<table>\n",
    "    <center><strong>MRKL Architecture</strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/mrkl.png\" width=80%>\n",
    "    </tr>\n",
    "    \n",
    "    Attribution: https://arxiv.org/pdf/2205.00445.pdf#page=2\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A LLM using MRKL is trained to make external calls to generate the answer:\n",
    "\n",
    "The prompt\n",
    "\n",
    "    What is 10 + 1 ?\n",
    "might generate response\n",
    "\n",
    "   CALCULATOR( 10 + 1 )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Program Aided LLM\n",
    "\n",
    "The [Program Aided Language Model](https://arxiv.org/pdf/2211.10435.pdf)\n",
    "- train the LLM to output *Python code* rather than text\n",
    "- the \"answer\" is obtained by using an external code interpreter on the generated text\n",
    "\n",
    "<table>\n",
    "    <center><strong>Program Aided Language Model</strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/program_aided_llm.png\" width=80%>\n",
    "    </tr>\n",
    "    \n",
    "    Attribution: https://arxiv.org/pdf/2211.10435.pdf#page=2\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "Some recent advances on solving multi-step quantitative reasoning\n",
    "problems can be found in\n",
    "- [Minerva: Solving Quantitative Reasoning Problems with Language Models](https://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# FinQA: Financial Question Answering \n",
    "\n",
    "The [FinQA dataset](https://arxiv.org/pdf/2109.00122.pdf)\n",
    "was created to test the ability of a model\n",
    "- to perform Question Answering in the domain of Finance\n",
    "- demonstrating the reasoning behind the answer\n",
    "    - by outputting a program to calculate the ansser\n",
    "\n",
    "<img src=\"images/finqa_ex.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The authors demonstrate a Retriever-Generator model for the task.\n",
    "- Retriever: External Knowledge Source to store Financial Reports on companies\n",
    "- Generator: outputs a \"calculator program\"\n",
    "\n",
    "Here we see both forms of extra-parametric capabilities integrated with a LLM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The authors of the FinQA dataset have also created the [ConvFinQA dataset](https://arxiv.org/pdf/2210.03849.pdf)\n",
    "- *conversational* question answering\n",
    "- a follow-up question can reference the answer to a previous question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "There are some obvious benefits to adding Extra Parametric capabilities to a LLM\n",
    "- The LLM can be smaller\n",
    "    - knowledge (factual and procedural) stored outside of parameters\n",
    "- New \"skills\" can be added via exemplars demonstrating calls to a new library\n",
    "    - Derivative pricing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
