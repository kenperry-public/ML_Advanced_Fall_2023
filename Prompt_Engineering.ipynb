{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\Reals}{{\\mathbb{R}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\Emb}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "\\def\\OrderOf#1{\\mathcal{O}\\left( #1 \\right)}\n",
       "%\n",
       "% Expectation operator\n",
       "\\def\\Exp#1{\\underset{#1} {\\operatorname{\\mathbb{E}}} }\n",
       "%\n",
       "% VAE\n",
       "\\def\\prs#1#2{\\mathcal{p}_{#2}(#1)}\n",
       "\\def\\qr#1{\\mathcal{q}(#1)}\n",
       "\\def\\qrs#1#2{\\mathcal{q}_{#2}(#1)}\n",
       "%\n",
       "% Reinforcement learning\n",
       "\\newcommand{\\Actions}{{\\mathcal{A}}} \n",
       "\\newcommand{\\actseq}{A}\n",
       "\\newcommand{\\act}{a}\n",
       "\\newcommand{\\States}{{\\mathcal{S}}}   \n",
       "\\newcommand{\\stateseq}{S}  \n",
       "\\newcommand{\\state}{s}\n",
       "\\newcommand{\\Rewards}{{\\mathcal{R}}}\n",
       "\\newcommand{\\rewseq}{R}\n",
       "\\newcommand{\\rew}{r}\n",
       "\\newcommand{\\transp}{P}\n",
       "\\newcommand{\\statevalfun}{v}\n",
       "\\newcommand{\\actvalfun}{q}\n",
       "\\newcommand{\\disc}{\\gamma}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prompt Engineering\n",
    "\n",
    "With the recent success of Assistants (like ChatGPT)\n",
    "- it is easy to reach the mistaken conclusion\n",
    "- that the Assistant is \"reasoning\"\n",
    "- when, in fact, it is doing nothing more than text-completion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review: Auto-regressive behavior of an LLM\n",
    "\n",
    "The user\n",
    "- inputs a sequence $\\x$ (e.g., the \"prompt\", i.e., a request for generating a response)\n",
    "- and expects a sequence $\\y$ (the response)\n",
    "- generated by the LLM according to probability distribution\n",
    "$$\n",
    "p( \\y | \\x )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The response sequence $\\y$ is generated *auto-regressively*:\n",
    "\n",
    "At position $\\tt$ of the output,\n",
    "- the Large Language Model  predicts the next token.\n",
    "$$\n",
    "\\hat{\\x}_\\tp \\in \\pr{ \\x_\\tp | \\x_{[0..\\tt-1]} }\n",
    "$$\n",
    "- conditional on all preceding tokens $\\x_{[0..\\tt-1]}$ in the sequence $\\x$\n",
    "    - the conditioning input is called the *context*\n",
    "- and extends the context by appending the prediction \n",
    "$$\n",
    "\\x = \\x_{[0..\\tt-1]} + \\hat\\x_\\tp\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Thus, at any step,  $\\x$ consists of\n",
    "-  the original user prompt as a prefix\n",
    "- followed by a suffix of the partially generated response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prompt Engineering: maximizing the chances of achieving a good response\n",
    "\n",
    "Given the auto-regressive generation process\n",
    "- the final response $\\y$ is therefore\n",
    "- *conditioned on all previously generated response tokens*\n",
    "- it is *path dependent*\n",
    "\n",
    "In order to generate a \"high quality\" $\\y$, we have to be aware of the path.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Prompt engineering*\n",
    "- is a collection of techniques\n",
    "- that attempt to generate paths\n",
    "- that lead to better responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example:\n",
    "- many tasks involve multiple steps of reason\n",
    "- asking\n",
    "    - directly for the answer\n",
    "    - is less likely to produce a correct response\n",
    "    - than asking for a step-by-step explanation to *proceed* the answer\n",
    "- that is\n",
    "    - having the LLM's response include the individual steps before the answer\n",
    "    - conditions it to produce the correct answer\n",
    "        - just like a human !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To illustrate: the following prompt involves a task whose solution has multiple steps of arithmetic reasoning\n",
    "\n",
    "            Each can contains 3 balls.\n",
    "            I start with 5 cans\n",
    "            At the end, all cans are empty except for one can with 2 balls.\n",
    "\n",
    "            How many balls did I use ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is not reasonable to expect text-completion to *immediately* generate the correct response.\n",
    "\n",
    "We can improve the chances of the LLM generating a correct response\n",
    "- just by appending \n",
    "\n",
    "        Let's think step by step\n",
    "    \n",
    "to the prompt !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is ChatGPT's response:\n",
    "\n",
    "<img src=\"images/cot_prompt_step_by_step.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Why does adding a simple request to think step-by-step work ?\n",
    "\n",
    "- The request causes the model to generate the response as a sequence of small steps\n",
    "- Step $\\tt$ is conditioned on all steps $\\tt' \\lt \\tt$\n",
    "- The probability of a correct answer on a small step is higher than on a large step (i.e, straight to answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The step-by-step approach\n",
    "- simulates reasoning\n",
    "- by turning it into text completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A word on Assistants\n",
    "\n",
    "The LLM's with which you may be familiar (e.g. ChatGPT) have been fine-tuned in several ways\n",
    "- to be a helpful assistant\n",
    "    - presume that your prompt is a request for service, a question that needs and answer, etc.\n",
    "- to be conversational\n",
    "- to be harmless and not dangerous\n",
    "\n",
    "Hence, your experience with an \"LLM\" may not correspond to our description of an LLM that has not been fine-tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is important to remember\n",
    "- that an LLM has **no memory**\n",
    "- The output $\\hat\\y_\\tp$ is solely a function of the prompt $\\x_{[0..\\tt-1]}$\n",
    "- So how is it that the Assistant seems to \"remember\" the prior parts of the interaction ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "An interaction with an Assistant is often a multi-round conversation\n",
    "- in round $i \\ge 0$\n",
    "    -  you enter prompt $\\x^\\ip$; get response $\\hat\\y^\\ip$\n",
    "- the *context* used to condition the response $\\hat\\y^{(i+1)}$\n",
    "    - is prompt $\\x^{(i+1)}$\n",
    "    - concatenated with the prompt/responses of earlier rounds\n",
    "- So \n",
    "$$\n",
    "\\hat\\y^{(i+1)} \\in \\pr{ \\y |  \\x^{(i+1)}, \\hat\\y^\\ip, \\x^\\ip, \\ldots, \\x^{(0)}, \\hat\\y^{(0)} }\n",
    "$$\n",
    "\n",
    "The Assistant \"remembers\" the entire conversation only by having it be part of the prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Resources\n",
    "\n",
    "There a lots of \"guides\" (some paid) that purport to turn you into a Prompting Wizard.\n",
    "\n",
    "Many of these are anecdotal.  We prefer measurement\n",
    "- guides that summarize empirical studies\n",
    "- and provide reference to the source paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [LearnPrompting.org Course](https://learnprompting.org/docs/intro)\n",
    "\n",
    "A fairly simple (free and open source) course\n",
    "- great way to find out what is interesting\n",
    "- **and** has references to papers so as to enable deeper understanding\n",
    "\n",
    "For example, some [basics](https://learnprompting.org/docs/category/-basics)\n",
    "- [role playing](https://learnprompting.org/docs/basics/roles) to control the style of output\n",
    "- [giving instructions](https://learnprompting.org/docs/basics/instructions) to *precisely* define the task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [Prompting Guide](https://www.promptingguide.ai/)\n",
    "\n",
    "Another fairly simple guide (ignore the promoted -- and paid -- course)\n",
    "- also has references to papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Case study\n",
    "\n",
    "\n",
    "- https://www.promptingguide.ai/applications/workplace_casestudy\n",
    "\n",
    "You can delve into various prompting techniques by examining the resources.\n",
    "\n",
    "As a short-cut\n",
    "- we will describe a few of the techniques\n",
    "- as part of a study evaluating techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One team decided to [measure the performance](https://arxiv.org/pdf/2303.07142.pdf) of various prompting techniques\n",
    "- using a **single** task as a case study\n",
    "- may not be able to generalize to other tasks\n",
    "\n",
    "Regardless of the limitations, a comparison is valuable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Methodology\n",
    "\n",
    "The task is a binary Classification task\n",
    "- given a job posting\n",
    "- classify whether the job listed is appropriate for a recent college graduate\n",
    "    - no experience needed and requires advanced education\n",
    "- UK based\n",
    "    - \"graduate\" means college graduate\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The metric used is \"precision at 95% recall\"\n",
    "- given that the model achieves a recall of at least 95%\n",
    "$$\n",
    "\\frac{\\text{TP}}{\\text{TP} + \\text{FN}} \\ge 95%\n",
    "$$\n",
    "- what is the precision (predicted Positives that are True Positives;minimize FP)\n",
    "$$\n",
    "\\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "$$\n",
    "\n",
    "The models evaluated are two variants of GPT 3.5 via OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prompt modifications evaluated\n",
    "\n",
    "\n",
    "<table>\n",
    "    <center><strong>Prompt modifications</strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/prompt_eng_case_study.png\" width=80%>\n",
    "    </tr>\n",
    "    \n",
    "    Attribution: https://arxiv.org/pdf/2303.07142.pdf#page=7\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Baseline\n",
    "\n",
    "Uses Keyword and Regular Expression search\n",
    "- \"Graduate\" or \"Junior\" in job title\n",
    "- \"suitable for graduate\" in body of posting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Chain of Thought (CoT): Few Shot\n",
    "\n",
    "Provide one or more exemplars for the task\n",
    "- where the exemplar demonstrates the correct response\n",
    "\n",
    "    \n",
    "The exemplars condition the LLM to produces responses\n",
    "- that look like the exemplars\n",
    "- so if the exemplars demonstrate step by step reasoning\n",
    "- the responses will hopefully do the same\n",
    "\n",
    "See panel (b) in the chart below\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <center><strong>Chain of Thought Prompting</strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/cot_step_by_step.png\" width=80%>\n",
    "    </tr>\n",
    "    \n",
    "    Attribution: https://arxiv.org/pdf/2201.11903.pdf\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Zero CoT: Chain of Thought: Zero shot\n",
    "\n",
    "- Append \"Let's think step by step\" to the base prompt\n",
    "    - see panel (d) in the chart above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Instructions: variants\n",
    "\n",
    "The prompt uses [Role prompting](https://learnprompting.org/docs/basics/roles)\n",
    "- the *role* the Assistant is to play in providing the response\n",
    "\n",
    ">You are an AI expert in career advice. You are tasked\n",
    "with sorting through jobs by analysing their content and\n",
    "deciding whether they would be a good fit for a recent\n",
    "graduate or not.\n",
    "    \n",
    "- giving [instructions](https://learnprompting.org/docs/basics/instructions) describing the task\n",
    "\n",
    ">A job is fit for a graduate if it's a junior-level\n",
    "position that does not require extensive prior professional\n",
    "experience. I will give you a job posting and you will\n",
    "analyse it, to know whether or not it describes a position\n",
    "fit for a graduate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The experiment was carried out in the [OpenAI Playground](https://platform.openai.com/playground).\n",
    "\n",
    "This tool has multiple input fields (System, User)\n",
    "- the following prompt techniques refer to placement in specific input areas\n",
    "- the actual prompt concatenates the two: System + User\n",
    "\n",
    "<img src=\"images/openai_playground.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### `rawinst`\n",
    "\n",
    "Role and Instruction placed in User Query field (top middle of page)\n",
    "\n",
    "#### `sysint`\n",
    "\n",
    "Role and Instruction placed in System Query field (to left of page)\n",
    "\n",
    "#### `bothinst`\n",
    "\n",
    "Role placed in System Query field; Instruction placed in User Query field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Mocked exchange (`mock`)\n",
    "\n",
    "This\n",
    "- creates an initial prompt to the Assistant, requesting that it confirm it's understanding (\"Got it ?\") of the Instructions in the User Query field\n",
    "- the prompt and response are then used as the value of the User Query field\n",
    "\n",
    "Variant of `bothinst` where \n",
    "- the User field becomes\n",
    "    >A job is fit for a graduate ... Got it ?\n",
    "    \n",
    "    >[Assistant response] Yes, I understand. I am ready to analyse your job posting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reiterating instructions (`reit`)\n",
    "\n",
    "Both the Role and the Instruction are reinforced by repetition.\n",
    "\n",
    "- Role\n",
    "    >You are an AI expert in career advice.  ... \n",
    "\n",
    "    >**Remember, you're the best AI careers expert\n",
    "    and will use your expertise to provide the best possible\n",
    "    analysis**\n",
    "- Instruction\n",
    "    >A job is fit for a graduate ...\n",
    "    >and you will analyse it, **step-by-step,** to know whether or not it describes ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Wording the prompt\n",
    "\n",
    "These involve appending the desired format of the response to the Instruction\n",
    "\n",
    "####  `loose`\n",
    ">Your answer must end with:\n",
    "\n",
    ">Final Answer: This is a (A) job fit for a recent graduate or\n",
    "a student OR (B) a job requiring more professional experience.\n",
    "\n",
    ">Answer: Let's think step-by-step,\n",
    "\n",
    "\n",
    "#### `strict`\n",
    "\n",
    ">You will answer following this template:\n",
    "\n",
    ">Reasoning step 1:\n",
    "\n",
    ">Reasoning step 2:\n",
    "\n",
    ">Reasoning step 3\n",
    "\n",
    ">Final Answer: This is a (A) job fit for a recent graduate or\n",
    "a student OR (B) a job requiring more professional experience.\n",
    "\n",
    ">Answer: Reasoning Step 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Right conclusion (`right`)\n",
    "\n",
    "Ask the model for step-by-step reasoning in order to arrive at the **right conclusion**\n",
    "\n",
    "> Let's think step-by-step **to reach the right conclusion,**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Again, let's remember that the LLM is performing text completion\n",
    "- one token at a time\n",
    "\n",
    "If any token in the sequence of results is not great\n",
    "- the final result will also not be great.\n",
    "\n",
    "The \"right conclusion\" prompt may cause the LLM to \n",
    "- re-evaluate how good an intermediate result is\n",
    "- rather than solely focusing on the high probability next token objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reasoning gaps (`info`)\n",
    "\n",
    "Prevent mis-interpretation of the Instructions\n",
    "\n",
    ">A job is fit for a graduate if it's a junior-level\n",
    "position that does not require extensive prior professional\n",
    "experience. \n",
    "\n",
    ">**When analysing the experience required, take\n",
    "into account that requiring internships is still fit for a\n",
    "graduate.**\n",
    "\n",
    ">I will give you a job posting and you will\n",
    "analyse it, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Subtle tweaks\n",
    "\n",
    "#### Giving the assistant a name (`name`)\n",
    "\n",
    "Give the assistant a name when describing its role.\n",
    "\n",
    "Change the Role from\n",
    ">You are an AI expert in career advice ...\n",
    "\n",
    "to\n",
    ">You are Sydney, an AI expert in career advice ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Positive feedback (`pos`)\n",
    "\n",
    "A modification of Mocked Exchange\n",
    "- after the Assistant confirms its understanding\n",
    "- give it positive feedback in the form of\n",
    ">Great! Let's begin then :)\n",
    "\n",
    "before continuing the mocked exchange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "The results are summarized in a table\n",
    "- Sub-metrics are reported to facilitate comparison\n",
    "    - rather than the ultimate metric of \"precision at 95% recall\"\n",
    "- *Template stickiness* refers to the format of the response\n",
    "    - the fraction of responses that conform to the desired format\n",
    "    - and don't need further parsing\n",
    "        - important for downstream uses and ease of evaluation\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <center><strong>Evaluation of Prompt modifications</strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/prompt_eng_case_study_results.png\" width=80%>\n",
    "    </tr>\n",
    "    \n",
    "    Attribution: https://arxiv.org/pdf/2303.07142.pdf#page=12\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### High level conclusions\n",
    "- Prompt formatting is important\n",
    "    - Final prompt greatly improves over Baseline\n",
    "        - F1: $65.6 \\leadsto 91.7$\n",
    "        - Recall: $70.6 \\leadsto 97$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Chain of Thought: more exemplars **don't improve** performance\n",
    "    - Zero shot(`Zero-CoT`) vs Few shot (`CoT`)\n",
    "        - F1: $81.4 \\leadsto  78.4$\n",
    "        - Precision $75.5 \\leadsto  72.6$\n",
    "    - Theories\n",
    "        - the task was sufficiently simple that exemplars weren't needed\n",
    "        - the exemplars thus\n",
    "            - increased Recall\n",
    "            - but decrease Precision\n",
    "        - We mentioned another theory in the [In Context Learning theory module](Prompt_Engineering_Suggestions.ipynb#Prompt-Programming-for-Large-Language-Models:-Beyond-the-Few-Shot-Paradigm)\n",
    "            - the role of exemplars is to *help locate* the desired task among the tasks seen in training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Role Prompting and Instructions lead to the biggest increase in performance under Zero shot CoT\n",
    "    - `Zero-CoT` $\\leadsto$ `+rawinst`\n",
    "        - F1: $81.4 \\leadsto 85.8$\n",
    "        - Precision: $75.5 \\leadsto 80$\n",
    "- Placement of Role and Instruction with Query fields is significant\n",
    "    - Why ?  Must not be simple concatenation as I conjectured\n",
    "    - `Zero-CoT` $\\leadsto$ `bothinst`\n",
    "        - F1: $81.4 \\leadsto 87.5$\n",
    "        - Precision: $75.5 \\leadsto 81.9$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Mocked exchange increase Recall\n",
    "    - `bothinst` $\\leadsto$ `bothinst + mock`\n",
    "        - Recall: $93.9 \\leadsto 95.1$\n",
    "        - above the desired 95% Recall threshold for the ultimate metric \"precision at 95% recall\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Repetition in prompts helps !  Combining leads to Final result that dominates all others.\n",
    "    - Re-iterating instructions (`reit`)\n",
    "    - Emphasizing Right conclusion (`right`)\n",
    "    - Emphasizing elminating Reasoning gaps ('info`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
